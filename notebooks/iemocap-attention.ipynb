{"cells":[{"metadata":{"_uuid":"468fb152-ab29-43fc-a3d8-8cb387cbd6c7","_cell_guid":"584c7127-634c-411c-b1cf-057f70762459","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport librosa\nimport matplotlib.pyplot as plt\nimport gc\n\nfrom tqdm import tqdm, tqdm_notebook\nfrom sklearn.metrics import label_ranking_average_precision_score\nfrom sklearn.model_selection import train_test_split\n\ntqdm.pandas()\n\nimport pickle,glob,sys\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nemotion_dict = {'ang': 0,'hap': 1,'exc': 2,'sad': 3,'fru': 4,'fea': 5,'sur': 6,'neu': 7,\n                'xxx': 8,'oth': 8,'dis': 8}\n\nemotion_full_dict = {'neu': 'neutral', 'ang': 'anger', 'hap': 'happiness', 'exc': 'excited', \n                    'sad': 'sadness', 'fru':'frustrated', 'fea': 'fear', 'sur': 'surprised', \n                     'xxx': 'others', 'oth': 'others', 'dis': 'others'}","execution_count":2,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/tqdm/std.py:666: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n  from pandas import Panel\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def split_and_label(rows_labels):\n    \n    row_labels_list = []\n    for row in rows_labels:\n        row_labels = row.split(',')\n        labels_array = np.zeros((4))\n        \n        for label in row_labels:\n            index = label_mapping[label]\n            labels_array[index] = 1\n        \n        row_labels_list.append(labels_array)\n    \n    return row_labels_list","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1 = pd.read_csv('../input/iemocap-audio-files-compressed/df_IEMOCAP/df_IEMOCAP/df_iemocap_1.csv')\ndf2 = pd.read_csv('../input/iemocap-audio-files-compressed/df_IEMOCAP/df_IEMOCAP/df_iemocap_2.csv')\ndf3 = pd.read_csv('../input/iemocap-audio-files-compressed/df_IEMOCAP/df_IEMOCAP/df_iemocap_3.csv')\ndf4 = pd.read_csv('../input/iemocap-audio-files-compressed/df_IEMOCAP/df_IEMOCAP/df_iemocap_4.csv')\ndf = pd.concat([df1,df2,df3,df4], ignore_index = True)\nTrain_df = df[df[\"emotion\"].isin([\"neu\", 'ang', 'hap', 'sad', 'exc'])]\nTrain_df = Train_df.replace('exc','hap')\nTrain_df['fname'] = Train_df['wav_file'].astype(str).apply(lambda x: x + '.opus')\nTrain_df = Train_df.drop(['start_time', 'end_time','val','act','dom','wav_file'], axis=1)\nTrain_df.emotion.value_counts()","execution_count":4,"outputs":[{"output_type":"execute_result","execution_count":4,"data":{"text/plain":"neu    1324\nhap    1194\nang     933\nsad     839\nName: emotion, dtype: int64"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"Train_df.head()","execution_count":5,"outputs":[{"output_type":"execute_result","execution_count":5,"data":{"text/plain":"  emotion                     fname\n0     neu  Ses01F_impro04_F000.opus\n1     neu  Ses01F_impro04_F001.opus\n5     neu  Ses01F_impro04_F005.opus\n6     neu  Ses01F_impro04_F006.opus\n9     neu  Ses01F_impro04_F009.opus","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>emotion</th>\n      <th>fname</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>neu</td>\n      <td>Ses01F_impro04_F000.opus</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>neu</td>\n      <td>Ses01F_impro04_F001.opus</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>neu</td>\n      <td>Ses01F_impro04_F005.opus</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>neu</td>\n      <td>Ses01F_impro04_F006.opus</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>neu</td>\n      <td>Ses01F_impro04_F009.opus</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"Test_df = pd.read_csv('../input/iemocap-audio-files-compressed/df_IEMOCAP/df_IEMOCAP/df_iemocap_5.csv')\nTest_df = Test_df[Test_df[\"emotion\"].isin([\"neu\", 'ang', 'hap', 'sad', 'exc'])]\nTest_df = Test_df.replace('exc','hap')\nTest_df['fname'] = Test_df['wav_file'].astype(str).apply(lambda x: x + '.opus')\nTest_df = Test_df.drop(['start_time', 'end_time','val','act','dom','wav_file'], axis=1)\nTest_df.head()","execution_count":6,"outputs":[{"output_type":"execute_result","execution_count":6,"data":{"text/plain":"  emotion                     fname\n0     hap  Ses05M_impro07_F000.opus\n1     hap  Ses05M_impro07_F001.opus\n3     hap  Ses05M_impro07_F003.opus\n4     hap  Ses05M_impro07_F004.opus\n5     hap  Ses05M_impro07_F005.opus","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>emotion</th>\n      <th>fname</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>hap</td>\n      <td>Ses05M_impro07_F000.opus</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>hap</td>\n      <td>Ses05M_impro07_F001.opus</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>hap</td>\n      <td>Ses05M_impro07_F003.opus</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>hap</td>\n      <td>Ses05M_impro07_F004.opus</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>hap</td>\n      <td>Ses05M_impro07_F005.opus</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(18,6))\n\nplt.subplot(121)\nax1 = Train_df['emotion'].sort_index().value_counts().plot(kind='bar')\nplt.xlabel('Number of labels')\nplt.ylabel('Counts')\nplt.xticks(rotation=0)\nplt.title('Training Set')\n\nfor p in ax1.patches:\n    ax1.annotate(str(p.get_height()), \n                (p.get_x() + p.get_width()/2., p.get_height() * 1.005), \n                ha='center',\n                va='center',\n                xytext=(0,5), \n                textcoords='offset points')\n\nplt.subplot(122)\nax2 = Test_df['emotion'].value_counts().sort_index().plot(kind='bar', )\nplt.xlabel('Number of labels')\nplt.ylabel('Counts')\nplt.xticks(rotation=0)\nplt.title('Test Set')\n\nfor p in ax2.patches:\n    ax2.annotate(str(p.get_height()), \n                (p.get_x() + p.get_width()/2., p.get_height() * 1.005), \n                ha='center',\n                va='center',\n                xytext=(0,5), \n                textcoords='offset points')\n\n    \nplt.show()","execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 1296x432 with 2 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import preprocessing\nle = preprocessing.LabelEncoder()\nle.fit(Train_df['emotion'])\nlabel_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\nprint(label_mapping)","execution_count":8,"outputs":[{"output_type":"stream","text":"{'ang': 0, 'hap': 1, 'neu': 2, 'sad': 3}\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"label_column = pd.Index(['ang', 'hap', 'neu','sad'])","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in tqdm(label_column):\n    Train_df[col] = 0\n    Test_df[col] = 0\n    \nprint(Train_df.shape, Test_df.shape)","execution_count":10,"outputs":[{"output_type":"stream","text":"100%|██████████| 4/4 [00:00<00:00, 795.43it/s]","name":"stderr"},{"output_type":"stream","text":"(4290, 6) (1241, 6)\n","name":"stdout"},{"output_type":"stream","text":"\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"Train_df.head()","execution_count":11,"outputs":[{"output_type":"execute_result","execution_count":11,"data":{"text/plain":"  emotion                     fname  ang  hap  neu  sad\n0     neu  Ses01F_impro04_F000.opus    0    0    0    0\n1     neu  Ses01F_impro04_F001.opus    0    0    0    0\n5     neu  Ses01F_impro04_F005.opus    0    0    0    0\n6     neu  Ses01F_impro04_F006.opus    0    0    0    0\n9     neu  Ses01F_impro04_F009.opus    0    0    0    0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>emotion</th>\n      <th>fname</th>\n      <th>ang</th>\n      <th>hap</th>\n      <th>neu</th>\n      <th>sad</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>neu</td>\n      <td>Ses01F_impro04_F000.opus</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>neu</td>\n      <td>Ses01F_impro04_F001.opus</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>neu</td>\n      <td>Ses01F_impro04_F005.opus</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>neu</td>\n      <td>Ses01F_impro04_F006.opus</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>neu</td>\n      <td>Ses01F_impro04_F009.opus</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"Train_df_labels = split_and_label(Train_df['emotion'])\nTest_df_labels = split_and_label(Test_df['emotion'])","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Train_df[label_column] = Train_df_labels\nTest_df[label_column] = Test_df_labels","execution_count":13,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Train_df['num_labels'] = Train_df[label_column].sum(axis=1)\nTest_df['num_labels'] = Test_df[label_column].sum(axis=1)","execution_count":14,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Test_df","execution_count":15,"outputs":[{"output_type":"execute_result","execution_count":15,"data":{"text/plain":"     emotion                     fname  ang  hap  neu  sad  num_labels\n0        hap  Ses05M_impro07_F000.opus  0.0  1.0  0.0  0.0         1.0\n1        hap  Ses05M_impro07_F001.opus  0.0  1.0  0.0  0.0         1.0\n3        hap  Ses05M_impro07_F003.opus  0.0  1.0  0.0  0.0         1.0\n4        hap  Ses05M_impro07_F004.opus  0.0  1.0  0.0  0.0         1.0\n5        hap  Ses05M_impro07_F005.opus  0.0  1.0  0.0  0.0         1.0\n...      ...                       ...  ...  ...  ...  ...         ...\n2162     sad  Ses05M_impro02_M025.opus  0.0  0.0  0.0  1.0         1.0\n2164     sad  Ses05M_impro02_M027.opus  0.0  0.0  0.0  1.0         1.0\n2165     sad  Ses05M_impro02_M028.opus  0.0  0.0  0.0  1.0         1.0\n2166     sad  Ses05M_impro02_M029.opus  0.0  0.0  0.0  1.0         1.0\n2167     hap  Ses05M_impro02_M030.opus  0.0  1.0  0.0  0.0         1.0\n\n[1241 rows x 7 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>emotion</th>\n      <th>fname</th>\n      <th>ang</th>\n      <th>hap</th>\n      <th>neu</th>\n      <th>sad</th>\n      <th>num_labels</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>hap</td>\n      <td>Ses05M_impro07_F000.opus</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>hap</td>\n      <td>Ses05M_impro07_F001.opus</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>hap</td>\n      <td>Ses05M_impro07_F003.opus</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>hap</td>\n      <td>Ses05M_impro07_F004.opus</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>hap</td>\n      <td>Ses05M_impro07_F005.opus</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2162</th>\n      <td>sad</td>\n      <td>Ses05M_impro02_M025.opus</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2164</th>\n      <td>sad</td>\n      <td>Ses05M_impro02_M027.opus</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2165</th>\n      <td>sad</td>\n      <td>Ses05M_impro02_M028.opus</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2166</th>\n      <td>sad</td>\n      <td>Ses05M_impro02_M029.opus</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2167</th>\n      <td>hap</td>\n      <td>Ses05M_impro02_M030.opus</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>1241 rows × 7 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Special thanks to https://github.com/makinacorpus/easydict/blob/master/easydict/__init__.py\n\nclass EasyDict(dict):\n\n    def __init__(self, d=None, **kwargs):\n        if d is None:\n            d = {}\n        if kwargs:\n            d.update(**kwargs)\n        for k, v in d.items():\n            setattr(self, k, v)\n        # Class attributes\n        for k in self.__class__.__dict__.keys():\n            if not (k.startswith('__') and k.endswith('__')) and not k in ('update', 'pop'):\n                setattr(self, k, getattr(self, k))\n\n    def __setattr__(self, name, value):\n        if isinstance(value, (list, tuple)):\n            value = [self.__class__(x)\n                     if isinstance(x, dict) else x for x in value]\n        elif isinstance(value, dict) and not isinstance(value, self.__class__):\n            value = self.__class__(value)\n        super(EasyDict, self).__setattr__(name, value)\n        super(EasyDict, self).__setitem__(name, value)\n\n    __setitem__ = __setattr__\n\n    def update(self, e=None, **f):\n        d = e or dict()\n        d.update(f)\n        for k in d:\n            setattr(self, k, d[k])\n\n    def pop(self, k, d=None):\n        delattr(self, k)\n        return super(EasyDict, self).pop(k, d)","execution_count":16,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"conf = EasyDict()\nconf.sampling_rate = 44100\nconf.duration = 5\nconf.hop_length = 347 # to make time steps 128\nconf.fmin = 20\nconf.fmax = conf.sampling_rate // 2\nconf.n_mels = 128\nconf.n_fft = conf.n_mels * 20\n\nconf.samples = conf.sampling_rate * conf.duration\n\nTrain_path = '../input/iemocap-audio-files-compressed/Train/Train/'\nTest_path = '../input/iemocap-audio-files-compressed/Compressed_audio/Compressed_audio/IEMOCAP_Compressed_br8_fs20/Session5/opus/'\n","execution_count":17,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def read_audio(conf, pathname, trim_long_data):\n    y, sr = librosa.load(pathname, sr=conf.sampling_rate)\n    # trim silence\n    if 0 < len(y): # workaround: 0 length causes error\n        y, _ = librosa.effects.trim(y) # trim, top_db=default(60)\n    # make it unified length to conf.samples\n    if len(y) > conf.samples: # long enough\n        if trim_long_data:\n            y = y[0:0+conf.samples]\n    else: # pad blank\n        padding = conf.samples - len(y)    # add padding at both ends\n        offset = padding // 2\n        y = np.pad(y, (offset, conf.samples - len(y) - offset), 'constant')\n    return y\n\ndef audio_to_melspectrogram(conf, audio):\n    spectrogram = librosa.feature.melspectrogram(audio, \n                                                 sr=conf.sampling_rate,\n                                                 n_mels=conf.n_mels,\n                                                 hop_length=conf.hop_length,\n                                                 n_fft=conf.n_fft,\n                                                 fmin=conf.fmin,\n                                                 fmax=conf.fmax)\n    spectrogram = librosa.power_to_db(spectrogram)\n    spectrogram = spectrogram.astype(np.float32)\n    return spectrogram\n\ndef read_as_melspectrogram(conf, pathname, trim_long_data, debug_display=False):\n    x = read_audio(conf, pathname, trim_long_data)\n    mels = audio_to_melspectrogram(conf, x)\n    if debug_display:\n        IPython.display.display(IPython.display.Audio(x, rate=conf.sampling_rate))\n        show_melspectrogram(conf, mels)\n    return mels\n\ndef convert_wav_to_image(df, source):\n    X = []\n    for i, row in tqdm_notebook(df.iterrows()):\n        try:\n            x = read_as_melspectrogram(conf, f'{source[0]}/{str(row.fname)}', trim_long_data=True)\n        except:\n            x = read_as_melspectrogram(conf, f'{source[1]}/{str(row.fname)}', trim_long_data=True)\n\n        #x_color = mono_to_color(x)\n        X.append(x.transpose())\n        #df.loc[i, 'length'] = x.shape[1]\n    return X","execution_count":18,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\n#X = np.array(convert_wav_to_image(train, source=[train_curated_path, train_noisy_path]))\nX = np.array(convert_wav_to_image(Train_df, source=[Train_path]))","execution_count":19,"outputs":[{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7c69dbe08c044ae0987d9337a63cdcc3"}},"metadata":{}},{"output_type":"stream","text":"\nCPU times: user 17min 22s, sys: 4min 8s, total: 21min 31s\nWall time: 28min 57s\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test = np.array(convert_wav_to_image(Test_df, source=[Test_path]))","execution_count":20,"outputs":[{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d9cfbe572d604a11be403e9d8282decb"}},"metadata":{}},{"output_type":"stream","text":"\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_train = Train_df[label_column].values\nY_test = Test_df[label_column].values","execution_count":21,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.shape","execution_count":22,"outputs":[{"output_type":"execute_result","execution_count":22,"data":{"text/plain":"(4290, 636, 128)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import keras\nfrom keras import backend as K\nfrom keras.engine.topology import Layer\nfrom keras import initializers, regularizers, constraints, optimizers, layers\nfrom keras.layers import Embedding, Input, Dense,GRU,LSTM,concatenate, Bidirectional, SpatialDropout1D, Conv1D, GlobalAveragePooling1D, GlobalMaxPooling1D, Dropout\nfrom keras.models import Model\nfrom keras.optimizers import Adam\nfrom keras.callbacks import EarlyStopping","execution_count":32,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Attention(keras.layers.Layer):\n    def __init__(self, step_dim,\n                 W_regularizer=None, b_regularizer=None,\n                 W_constraint=None, b_constraint=None,\n                 bias=True, **kwargs):\n        self.supports_masking = True\n        self.init = initializers.get('glorot_uniform')\n\n        self.W_regularizer = regularizers.get(W_regularizer)\n        self.b_regularizer = regularizers.get(b_regularizer)\n\n        self.W_constraint = constraints.get(W_constraint)\n        self.b_constraint = constraints.get(b_constraint)\n\n        self.bias = bias\n        self.step_dim = step_dim\n        self.features_dim = 0\n        super(Attention, self).__init__(**kwargs)\n\n    def build(self, input_shape):\n        assert len(input_shape) == 3\n\n        self.W = self.add_weight(shape = (input_shape[-1],),\n                                 initializer=self.init,\n                                 name='{}_W'.format(self.name),\n                                 regularizer=self.W_regularizer,\n                                 constraint=self.W_constraint)\n        self.features_dim = input_shape[-1]\n\n        if self.bias:\n            self.b = self.add_weight(shape = (input_shape[1],),\n                                     initializer='zero',\n                                     name='{}_b'.format(self.name),\n                                     regularizer=self.b_regularizer,\n                                     constraint=self.b_constraint)\n        else:\n            self.b = None\n\n        self.built = True\n\n    def compute_mask(self, input, input_mask=None):\n        return None\n\n    def call(self, x, mask=None):\n        features_dim = self.features_dim\n        step_dim = self.step_dim\n\n        eij = K.reshape(K.dot(K.reshape(x, (-1, features_dim)),\n                        K.reshape(self.W, (features_dim, 1))), (-1, step_dim))\n\n        if self.bias:\n            eij += self.b\n\n        eij = K.tanh(eij)\n\n        a = K.exp(eij)\n\n        if mask is not None:\n            a *= K.cast(mask, K.floatx())\n\n        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n\n        a = K.expand_dims(a)\n        weighted_input = x * a\n        return K.sum(weighted_input, axis=1)\n\n    def compute_output_shape(self, input_shape):\n        return input_shape[0],  self.features_dim","execution_count":33,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sequence_input = Input(shape=(636,128), dtype='float32')\nx = LSTM(256, return_sequences=True)(sequence_input) \natt = Attention(636)(x)\navg_pool = GlobalAveragePooling1D()(x)\nmax_pool = GlobalMaxPooling1D()(x) \n\nx = concatenate([att, avg_pool, max_pool])\n\npreds = Dense(4, activation='softmax')(x)\n\nmodel = Model(sequence_input, preds)\nmodel.summary()","execution_count":39,"outputs":[{"output_type":"stream","text":"Model: \"functional_5\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_4 (InputLayer)            [(None, 636, 128)]   0                                            \n__________________________________________________________________________________________________\nlstm_1 (LSTM)                   (None, 636, 256)     394240      input_4[0][0]                    \n__________________________________________________________________________________________________\nattention_2 (Attention)         (None, 256)          892         lstm_1[0][0]                     \n__________________________________________________________________________________________________\nglobal_average_pooling1d_2 (Glo (None, 256)          0           lstm_1[0][0]                     \n__________________________________________________________________________________________________\nglobal_max_pooling1d_2 (GlobalM (None, 256)          0           lstm_1[0][0]                     \n__________________________________________________________________________________________________\nconcatenate_2 (Concatenate)     (None, 768)          0           attention_2[0][0]                \n                                                                 global_average_pooling1d_2[0][0] \n                                                                 global_max_pooling1d_2[0][0]     \n__________________________________________________________________________________________________\ndense_2 (Dense)                 (None, 4)            3076        concatenate_2[0][0]              \n==================================================================================================\nTotal params: 398,208\nTrainable params: 398,208\nNon-trainable params: 0\n__________________________________________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(loss='categorical_crossentropy',optimizer=Adam(0.005),metrics=['accuracy'])","execution_count":40,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"assert len(X) == len(Y_train)\nassert len(X_test) == len(Y_test)","execution_count":41,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#es = EarlyStopping(monitor='val_accuracy', mode='max', verbose=1, patience=3)","execution_count":42,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(np.array(X),\n          Y_train,\n          batch_size=1024,\n          epochs=100,\n          validation_data=(np.array(X_test), Y_test),\n          )","execution_count":43,"outputs":[{"output_type":"stream","text":"Epoch 1/100\n5/5 [==============================] - 3s 595ms/step - loss: 2.2373 - accuracy: 0.2641 - val_loss: 1.3301 - val_accuracy: 0.3400\nEpoch 2/100\n5/5 [==============================] - 2s 455ms/step - loss: 1.4590 - accuracy: 0.3387 - val_loss: 1.2995 - val_accuracy: 0.3255\nEpoch 3/100\n5/5 [==============================] - 2s 489ms/step - loss: 1.3100 - accuracy: 0.3837 - val_loss: 1.3281 - val_accuracy: 0.3006\nEpoch 4/100\n5/5 [==============================] - 2s 454ms/step - loss: 1.2803 - accuracy: 0.3858 - val_loss: 1.2639 - val_accuracy: 0.3570\nEpoch 5/100\n5/5 [==============================] - 2s 487ms/step - loss: 1.2436 - accuracy: 0.4016 - val_loss: 1.2246 - val_accuracy: 0.3956\nEpoch 6/100\n5/5 [==============================] - 2s 477ms/step - loss: 1.2036 - accuracy: 0.4156 - val_loss: 1.2099 - val_accuracy: 0.4367\nEpoch 7/100\n5/5 [==============================] - 3s 503ms/step - loss: 1.1625 - accuracy: 0.4583 - val_loss: 1.1826 - val_accuracy: 0.4271\nEpoch 8/100\n5/5 [==============================] - 2s 455ms/step - loss: 1.1387 - accuracy: 0.4529 - val_loss: 1.1761 - val_accuracy: 0.4827\nEpoch 9/100\n5/5 [==============================] - 2s 453ms/step - loss: 1.1232 - accuracy: 0.4893 - val_loss: 1.1515 - val_accuracy: 0.4577\nEpoch 10/100\n5/5 [==============================] - 2s 480ms/step - loss: 1.1120 - accuracy: 0.5026 - val_loss: 1.1587 - val_accuracy: 0.4569\nEpoch 11/100\n5/5 [==============================] - 2s 471ms/step - loss: 1.1002 - accuracy: 0.4993 - val_loss: 1.1678 - val_accuracy: 0.4303\nEpoch 12/100\n5/5 [==============================] - 2s 482ms/step - loss: 1.1059 - accuracy: 0.5023 - val_loss: 1.1776 - val_accuracy: 0.4158\nEpoch 13/100\n5/5 [==============================] - 2s 462ms/step - loss: 1.1042 - accuracy: 0.4953 - val_loss: 1.1425 - val_accuracy: 0.4658\nEpoch 14/100\n5/5 [==============================] - 2s 475ms/step - loss: 1.0944 - accuracy: 0.5033 - val_loss: 1.1666 - val_accuracy: 0.4311\nEpoch 15/100\n5/5 [==============================] - 2s 483ms/step - loss: 1.0991 - accuracy: 0.4939 - val_loss: 1.2293 - val_accuracy: 0.4045\nEpoch 16/100\n5/5 [==============================] - 2s 457ms/step - loss: 1.1133 - accuracy: 0.4858 - val_loss: 1.1820 - val_accuracy: 0.4351\nEpoch 17/100\n5/5 [==============================] - 2s 453ms/step - loss: 1.1080 - accuracy: 0.4876 - val_loss: 1.1491 - val_accuracy: 0.4214\nEpoch 18/100\n5/5 [==============================] - 2s 495ms/step - loss: 1.1107 - accuracy: 0.4774 - val_loss: 1.1483 - val_accuracy: 0.4746\nEpoch 19/100\n5/5 [==============================] - 3s 575ms/step - loss: 1.1192 - accuracy: 0.4753 - val_loss: 1.1822 - val_accuracy: 0.4319\nEpoch 20/100\n5/5 [==============================] - 2s 451ms/step - loss: 1.1024 - accuracy: 0.4741 - val_loss: 1.1968 - val_accuracy: 0.4093\nEpoch 21/100\n5/5 [==============================] - 2s 483ms/step - loss: 1.1075 - accuracy: 0.4809 - val_loss: 1.1419 - val_accuracy: 0.4795\nEpoch 22/100\n5/5 [==============================] - 2s 473ms/step - loss: 1.1088 - accuracy: 0.4751 - val_loss: 1.1946 - val_accuracy: 0.4142\nEpoch 23/100\n5/5 [==============================] - 2s 457ms/step - loss: 1.1240 - accuracy: 0.4716 - val_loss: 1.1959 - val_accuracy: 0.3666\nEpoch 24/100\n5/5 [==============================] - 2s 475ms/step - loss: 1.1037 - accuracy: 0.4802 - val_loss: 1.1602 - val_accuracy: 0.4376\nEpoch 25/100\n5/5 [==============================] - 2s 461ms/step - loss: 1.0970 - accuracy: 0.4823 - val_loss: 1.1761 - val_accuracy: 0.4617\nEpoch 26/100\n5/5 [==============================] - 2s 463ms/step - loss: 1.0969 - accuracy: 0.4925 - val_loss: 1.1672 - val_accuracy: 0.4593\nEpoch 27/100\n5/5 [==============================] - 2s 468ms/step - loss: 1.0856 - accuracy: 0.4872 - val_loss: 1.1482 - val_accuracy: 0.4827\nEpoch 28/100\n5/5 [==============================] - 2s 479ms/step - loss: 1.0842 - accuracy: 0.4967 - val_loss: 1.1870 - val_accuracy: 0.4198\nEpoch 29/100\n5/5 [==============================] - 2s 457ms/step - loss: 1.0802 - accuracy: 0.4960 - val_loss: 1.1592 - val_accuracy: 0.4327\nEpoch 30/100\n5/5 [==============================] - 3s 515ms/step - loss: 1.0822 - accuracy: 0.5044 - val_loss: 1.1695 - val_accuracy: 0.4384\nEpoch 31/100\n5/5 [==============================] - 2s 489ms/step - loss: 1.0790 - accuracy: 0.5014 - val_loss: 1.1543 - val_accuracy: 0.4255\nEpoch 32/100\n5/5 [==============================] - 2s 479ms/step - loss: 1.0755 - accuracy: 0.5100 - val_loss: 1.1430 - val_accuracy: 0.4649\nEpoch 33/100\n5/5 [==============================] - 2s 476ms/step - loss: 1.0623 - accuracy: 0.5217 - val_loss: 1.1416 - val_accuracy: 0.4521\nEpoch 34/100\n5/5 [==============================] - 2s 466ms/step - loss: 1.0599 - accuracy: 0.5110 - val_loss: 1.1805 - val_accuracy: 0.4182\nEpoch 35/100\n5/5 [==============================] - 2s 498ms/step - loss: 1.0654 - accuracy: 0.5177 - val_loss: 1.1698 - val_accuracy: 0.4319\nEpoch 36/100\n5/5 [==============================] - 2s 482ms/step - loss: 1.0785 - accuracy: 0.4965 - val_loss: 1.1372 - val_accuracy: 0.4754\nEpoch 37/100\n5/5 [==============================] - 2s 479ms/step - loss: 1.0949 - accuracy: 0.4790 - val_loss: 1.2521 - val_accuracy: 0.4247\nEpoch 38/100\n5/5 [==============================] - 2s 476ms/step - loss: 1.0910 - accuracy: 0.4858 - val_loss: 1.1465 - val_accuracy: 0.4456\nEpoch 39/100\n5/5 [==============================] - 3s 541ms/step - loss: 1.0868 - accuracy: 0.4844 - val_loss: 1.1718 - val_accuracy: 0.4327\nEpoch 40/100\n5/5 [==============================] - 2s 472ms/step - loss: 1.0788 - accuracy: 0.4883 - val_loss: 1.1773 - val_accuracy: 0.4255\nEpoch 41/100\n5/5 [==============================] - 2s 495ms/step - loss: 1.0746 - accuracy: 0.5047 - val_loss: 1.1631 - val_accuracy: 0.4416\nEpoch 42/100\n5/5 [==============================] - 3s 551ms/step - loss: 1.0759 - accuracy: 0.5082 - val_loss: 1.2078 - val_accuracy: 0.4093\nEpoch 43/100\n5/5 [==============================] - 2s 455ms/step - loss: 1.0867 - accuracy: 0.4883 - val_loss: 1.1664 - val_accuracy: 0.4287\nEpoch 44/100\n5/5 [==============================] - 2s 490ms/step - loss: 1.0733 - accuracy: 0.5219 - val_loss: 1.1349 - val_accuracy: 0.4472\nEpoch 45/100\n5/5 [==============================] - 2s 466ms/step - loss: 1.0673 - accuracy: 0.4993 - val_loss: 1.1779 - val_accuracy: 0.4222\nEpoch 46/100\n5/5 [==============================] - 2s 474ms/step - loss: 1.0554 - accuracy: 0.5152 - val_loss: 1.1299 - val_accuracy: 0.4658\nEpoch 47/100\n5/5 [==============================] - 2s 452ms/step - loss: 1.0602 - accuracy: 0.5140 - val_loss: 1.1768 - val_accuracy: 0.4351\nEpoch 48/100\n5/5 [==============================] - 2s 482ms/step - loss: 1.0503 - accuracy: 0.5172 - val_loss: 1.1168 - val_accuracy: 0.4778\nEpoch 49/100\n5/5 [==============================] - 2s 455ms/step - loss: 1.0427 - accuracy: 0.5303 - val_loss: 1.1539 - val_accuracy: 0.4392\nEpoch 50/100\n5/5 [==============================] - 2s 490ms/step - loss: 1.0537 - accuracy: 0.5177 - val_loss: 1.1742 - val_accuracy: 0.4376\nEpoch 51/100\n5/5 [==============================] - 2s 463ms/step - loss: 1.0497 - accuracy: 0.5212 - val_loss: 1.1259 - val_accuracy: 0.4883\nEpoch 52/100\n5/5 [==============================] - 2s 464ms/step - loss: 1.0618 - accuracy: 0.5154 - val_loss: 1.1444 - val_accuracy: 0.4327\nEpoch 53/100\n5/5 [==============================] - 3s 528ms/step - loss: 1.0483 - accuracy: 0.5126 - val_loss: 1.2036 - val_accuracy: 0.4206\nEpoch 54/100\n5/5 [==============================] - 2s 480ms/step - loss: 1.0621 - accuracy: 0.5068 - val_loss: 1.1314 - val_accuracy: 0.4698\nEpoch 55/100\n5/5 [==============================] - 2s 483ms/step - loss: 1.0552 - accuracy: 0.5142 - val_loss: 1.1157 - val_accuracy: 0.4803\nEpoch 56/100\n5/5 [==============================] - 2s 483ms/step - loss: 1.0561 - accuracy: 0.5131 - val_loss: 1.1540 - val_accuracy: 0.4440\nEpoch 57/100\n5/5 [==============================] - 2s 463ms/step - loss: 1.0585 - accuracy: 0.5249 - val_loss: 1.2114 - val_accuracy: 0.4343\nEpoch 58/100\n5/5 [==============================] - 3s 518ms/step - loss: 1.0582 - accuracy: 0.5214 - val_loss: 1.1625 - val_accuracy: 0.4480\n","name":"stdout"},{"output_type":"stream","text":"Epoch 59/100\n5/5 [==============================] - 2s 463ms/step - loss: 1.0533 - accuracy: 0.5231 - val_loss: 1.1134 - val_accuracy: 0.4899\nEpoch 60/100\n5/5 [==============================] - 2s 499ms/step - loss: 1.0639 - accuracy: 0.4970 - val_loss: 1.1641 - val_accuracy: 0.4384\nEpoch 61/100\n5/5 [==============================] - 2s 452ms/step - loss: 1.0492 - accuracy: 0.5287 - val_loss: 1.1633 - val_accuracy: 0.4416\nEpoch 62/100\n5/5 [==============================] - 3s 514ms/step - loss: 1.0447 - accuracy: 0.5298 - val_loss: 1.1268 - val_accuracy: 0.4569\nEpoch 63/100\n5/5 [==============================] - 2s 452ms/step - loss: 1.0449 - accuracy: 0.5256 - val_loss: 1.1643 - val_accuracy: 0.4327\nEpoch 64/100\n5/5 [==============================] - 3s 504ms/step - loss: 1.0399 - accuracy: 0.5249 - val_loss: 1.1304 - val_accuracy: 0.4529\nEpoch 65/100\n5/5 [==============================] - 2s 476ms/step - loss: 1.0506 - accuracy: 0.5159 - val_loss: 1.1511 - val_accuracy: 0.4569\nEpoch 66/100\n5/5 [==============================] - 2s 499ms/step - loss: 1.0432 - accuracy: 0.5154 - val_loss: 1.1412 - val_accuracy: 0.4674\nEpoch 67/100\n5/5 [==============================] - 2s 477ms/step - loss: 1.0382 - accuracy: 0.5389 - val_loss: 1.1280 - val_accuracy: 0.4601\nEpoch 68/100\n5/5 [==============================] - 2s 480ms/step - loss: 1.0291 - accuracy: 0.5373 - val_loss: 1.1279 - val_accuracy: 0.4674\nEpoch 69/100\n5/5 [==============================] - 2s 457ms/step - loss: 1.0285 - accuracy: 0.5256 - val_loss: 1.1862 - val_accuracy: 0.4303\nEpoch 70/100\n5/5 [==============================] - 2s 494ms/step - loss: 1.0376 - accuracy: 0.5240 - val_loss: 1.1362 - val_accuracy: 0.4883\nEpoch 71/100\n5/5 [==============================] - 2s 469ms/step - loss: 1.0406 - accuracy: 0.5254 - val_loss: 1.1313 - val_accuracy: 0.4569\nEpoch 72/100\n5/5 [==============================] - 2s 457ms/step - loss: 1.0504 - accuracy: 0.5266 - val_loss: 1.1221 - val_accuracy: 0.4633\nEpoch 73/100\n5/5 [==============================] - 2s 456ms/step - loss: 1.0366 - accuracy: 0.5203 - val_loss: 1.1436 - val_accuracy: 0.4512\nEpoch 74/100\n5/5 [==============================] - 2s 468ms/step - loss: 1.0281 - accuracy: 0.5270 - val_loss: 1.2048 - val_accuracy: 0.4392\nEpoch 75/100\n5/5 [==============================] - 2s 461ms/step - loss: 1.0372 - accuracy: 0.5336 - val_loss: 1.1120 - val_accuracy: 0.4956\nEpoch 76/100\n5/5 [==============================] - 3s 531ms/step - loss: 1.0405 - accuracy: 0.5385 - val_loss: 1.1573 - val_accuracy: 0.4448\nEpoch 77/100\n5/5 [==============================] - 2s 452ms/step - loss: 1.0429 - accuracy: 0.5228 - val_loss: 1.1512 - val_accuracy: 0.4633\nEpoch 78/100\n5/5 [==============================] - 3s 502ms/step - loss: 1.0430 - accuracy: 0.5240 - val_loss: 1.1660 - val_accuracy: 0.4448\nEpoch 79/100\n5/5 [==============================] - 2s 468ms/step - loss: 1.0337 - accuracy: 0.5312 - val_loss: 1.1330 - val_accuracy: 0.4327\nEpoch 80/100\n5/5 [==============================] - 2s 468ms/step - loss: 1.0240 - accuracy: 0.5399 - val_loss: 1.1163 - val_accuracy: 0.4601\nEpoch 81/100\n5/5 [==============================] - 2s 453ms/step - loss: 1.0268 - accuracy: 0.5289 - val_loss: 1.1599 - val_accuracy: 0.4521\nEpoch 82/100\n5/5 [==============================] - 3s 541ms/step - loss: 1.0326 - accuracy: 0.5329 - val_loss: 1.1330 - val_accuracy: 0.4746\nEpoch 83/100\n5/5 [==============================] - 2s 463ms/step - loss: 1.0341 - accuracy: 0.5347 - val_loss: 1.1773 - val_accuracy: 0.4464\nEpoch 84/100\n5/5 [==============================] - 2s 488ms/step - loss: 1.0388 - accuracy: 0.5382 - val_loss: 1.1348 - val_accuracy: 0.4980\nEpoch 85/100\n5/5 [==============================] - 2s 460ms/step - loss: 1.0396 - accuracy: 0.5387 - val_loss: 1.1508 - val_accuracy: 0.4706\nEpoch 86/100\n5/5 [==============================] - 2s 474ms/step - loss: 1.0283 - accuracy: 0.5343 - val_loss: 1.1607 - val_accuracy: 0.4416\nEpoch 87/100\n5/5 [==============================] - 2s 486ms/step - loss: 1.0289 - accuracy: 0.5375 - val_loss: 1.1483 - val_accuracy: 0.4480\nEpoch 88/100\n5/5 [==============================] - 3s 504ms/step - loss: 1.0255 - accuracy: 0.5438 - val_loss: 1.0958 - val_accuracy: 0.4956\nEpoch 89/100\n5/5 [==============================] - 2s 468ms/step - loss: 1.0283 - accuracy: 0.5350 - val_loss: 1.1575 - val_accuracy: 0.4392\nEpoch 90/100\n5/5 [==============================] - 2s 495ms/step - loss: 1.0201 - accuracy: 0.5261 - val_loss: 1.1463 - val_accuracy: 0.4480\nEpoch 91/100\n5/5 [==============================] - 2s 492ms/step - loss: 1.0111 - accuracy: 0.5385 - val_loss: 1.1346 - val_accuracy: 0.4609\nEpoch 92/100\n5/5 [==============================] - 2s 485ms/step - loss: 1.0093 - accuracy: 0.5431 - val_loss: 1.1346 - val_accuracy: 0.4666\nEpoch 93/100\n5/5 [==============================] - 2s 491ms/step - loss: 1.0178 - accuracy: 0.5284 - val_loss: 1.2805 - val_accuracy: 0.3924\nEpoch 94/100\n5/5 [==============================] - 2s 486ms/step - loss: 1.0692 - accuracy: 0.4988 - val_loss: 1.1249 - val_accuracy: 0.4907\nEpoch 95/100\n5/5 [==============================] - 2s 458ms/step - loss: 1.0507 - accuracy: 0.5182 - val_loss: 1.1163 - val_accuracy: 0.4658\nEpoch 96/100\n5/5 [==============================] - 2s 479ms/step - loss: 1.0588 - accuracy: 0.5242 - val_loss: 1.1670 - val_accuracy: 0.4424\nEpoch 97/100\n5/5 [==============================] - 2s 465ms/step - loss: 1.0390 - accuracy: 0.5203 - val_loss: 1.1049 - val_accuracy: 0.4803\nEpoch 98/100\n5/5 [==============================] - 2s 462ms/step - loss: 1.0292 - accuracy: 0.5252 - val_loss: 1.1155 - val_accuracy: 0.4746\nEpoch 99/100\n5/5 [==============================] - 3s 503ms/step - loss: 1.0277 - accuracy: 0.5212 - val_loss: 1.1470 - val_accuracy: 0.4456\nEpoch 100/100\n5/5 [==============================] - 2s 441ms/step - loss: 1.0258 - accuracy: 0.5324 - val_loss: 1.1063 - val_accuracy: 0.5077\n","name":"stdout"},{"output_type":"execute_result","execution_count":43,"data":{"text/plain":"<tensorflow.python.keras.callbacks.History at 0x7f72acb8ec50>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train_pred = model.predict(np.array(X))\ny_val_pred = model.predict(np.array(X_test))","execution_count":45,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train_pred","execution_count":46,"outputs":[{"output_type":"execute_result","execution_count":46,"data":{"text/plain":"array([[0.1633101 , 0.42226124, 0.38830793, 0.02612071],\n       [0.27129006, 0.4857704 , 0.225874  , 0.01706556],\n       [0.02690162, 0.13753916, 0.38928825, 0.44627097],\n       ...,\n       [0.01940487, 0.10332402, 0.21386278, 0.6634084 ],\n       [0.51191163, 0.4210088 , 0.05173885, 0.01534076],\n       [0.22189067, 0.44212374, 0.30239627, 0.03358935]], dtype=float32)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train_pred = model.predict(np.array(X))\ny_test_pred = model.predict(np.array(X_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds=y_val_pred.argmax(axis=1)\n\nprint(preds)","execution_count":50,"outputs":[{"output_type":"stream","text":"[2 1 1 ... 1 1 1]\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = preds.astype(int).flatten()\npreds = (le.inverse_transform((preds)))\npreds = pd.DataFrame({'predictedvalues': preds})\n\n# Actual labels\nactual=Y_test.argmax(axis=1)\nactual = actual.astype(int).flatten()\nactual = (le.inverse_transform((actual)))\nactual = pd.DataFrame({'actualvalues': actual})\n\n# Lets combined both of them into a single dataframe\nfinaldf = actual.join(preds)\n\n# Write out the predictions to disk\nfinaldf.to_csv('Predictions.csv', index=False)\nprint(finaldf.groupby('predictedvalues').count())\n","execution_count":53,"outputs":[{"output_type":"stream","text":"                 actualvalues\npredictedvalues              \nang                        77\nhap                       429\nneu                       421\nsad                       314\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndef print_confusion_matrix(confusion_matrix, class_names, figsize = (10,7), fontsize=14):\n    \"\"\"Prints a confusion matrix, as returned by sklearn.metrics.confusion_matrix, as a heatmap.\n    \n    Arguments\n    ---------\n    confusion_matrix: numpy.ndarray\n        The numpy.ndarray object returned from a call to sklearn.metrics.confusion_matrix. \n        Similarly constructed ndarrays can also be used.\n    class_names: list\n        An ordered list of class names, in the order they index the given confusion matrix.\n    figsize: tuple\n        A 2-long tuple, the first value determining the horizontal size of the ouputted figure,\n        the second determining the vertical size. Defaults to (10,7).\n    fontsize: int\n        Font size for axes labels. Defaults to 14.\n        \n    Returns\n    -------\n    matplotlib.figure.Figure\n        The resulting confusion matrix figure\n    \"\"\"\n    df_cm = pd.DataFrame(\n        confusion_matrix, index=class_names, columns=class_names, \n    )\n    fig = plt.figure(figsize=figsize)\n    try:\n        heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n    except ValueError:\n        raise ValueError(\"Confusion matrix values must be integers.\")\n        \n    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=fontsize)\n    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize=fontsize)\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')","execution_count":54,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"finaldf = pd.read_csv(\"./Predictions.csv\")\nclasses = finaldf.actualvalues.unique()\nclasses.sort()    \nfrom sklearn.metrics import confusion_matrix, accuracy_score, classification_report\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n# Confusion matrix \nc = confusion_matrix(finaldf.actualvalues, finaldf.predictedvalues)\nprint(accuracy_score(finaldf.actualvalues, finaldf.predictedvalues))\nplt.show(print_confusion_matrix(c, class_names = classes))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}