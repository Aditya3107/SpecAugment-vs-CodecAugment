{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport os\nimport sys\n\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nimport tensorflow as tf\nimport keras\nfrom keras import regularizers\nfrom keras.preprocessing import sequence\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.models import Sequential, Model, model_from_json\nfrom keras.layers import Dense, Embedding, LSTM\nfrom keras.layers import Input, Flatten, Dropout, Activation, BatchNormalization\nfrom keras.layers import Conv1D, MaxPooling1D, AveragePooling1D\nfrom keras.utils import np_utils, to_categorical\nfrom keras.callbacks import ModelCheckpoint","execution_count":1,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"def feature_dataframe_gen(feature_dir):\n    feature_dataframe = []\n    for sess in range(1,6) :\n        feature_df = pd.read_csv('{}audio_features_{}.csv'.format(feature_dir,sess))\n        feature_df = feature_df.sample(frac=1,random_state = 50).reset_index(drop = True)\n        feature_dataframe.append(feature_df)\n    feature_dataframe = (pd.concat(feature_dataframe)).fillna(0)\n    feature_dataframe = feature_dataframe.replace('exc','hap')\n    #feature_dataframe = feature_dataframe.drop(feature_dataframe[feature_dataframe.emotions.isin([\"sur\", \"fea\"])].index)\n    return feature_dataframe","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ori_feature_dataframe = feature_dataframe_gen(feature_dir = '../input/iemocap-audio-features/')","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"spec_feature_dataframe = feature_dataframe_gen(feature_dir = '../input/iemocap-specaugmented/')","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ori_feature_dataframe = ori_feature_dataframe.loc[:, (ori_feature_dataframe==0.0).mean() < .9]","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"spec_feature_dataframe = spec_feature_dataframe.loc[:, (spec_feature_dataframe==0.0).mean() < .9]","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_ori, X_test_ori, y_train_ori, y_test_ori = train_test_split(ori_feature_dataframe.drop('emotions',1), ori_feature_dataframe.emotions, test_size = 0.20, shuffle = True, random_state = 42)","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_spec, X_test_spec, y_train_spec, y_test_spec = train_test_split(spec_feature_dataframe.drop('emotions',1), spec_feature_dataframe.emotions, test_size = 0.20, shuffle = True, random_state = 42)","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n#X_train = X_train_ori\n#y_train = y_train_ori\nX_train = pd.concat([X_train_ori,X_train_spec]).fillna(0)\ny_train = pd.concat([y_train_ori,y_train_spec])\nX_test = X_test_ori\ny_test = y_test_ori\n\n\nmean = np.mean(X_train, axis=0)\nstd = np.std(X_train, axis=0)\nX_train = ((X_train - mean)/std)\nX_test = ((X_test - mean)/std)","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = np.array(X_train)\ny_train = np.array(y_train)\nX_test = np.array(X_test)\ny_test = np.array(y_test)\n\n\nlb = LabelEncoder()\ny_train = np_utils.to_categorical(lb.fit_transform(y_train))\ny_test = np_utils.to_categorical(lb.fit_transform(y_test))\n\nX_train = np.expand_dims(X_train, axis = 2)\nX_test = np.expand_dims(X_test, axis = 2)","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nmodel = Sequential()\n\nmodel.add(Conv1D(256, 8, padding='same',input_shape=(X_train.shape[1],1)))  # X_train.shape[1] = No. of Columns\nmodel.add(Activation('relu'))\nmodel.add(Conv1D(256, 8, padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.05))\nmodel.add(MaxPooling1D(pool_size=(8)))\n\nmodel.add(Conv1D(128, 8, padding='same'))\nmodel.add(Activation('relu'))\n\nmodel.add(Conv1D(128, 8, padding='same'))\nmodel.add(Activation('relu'))\n\nmodel.add(Conv1D(128, 8, padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.10))\nmodel.add(MaxPooling1D(pool_size=(8)))\n\nmodel.add(Conv1D(64, 8, padding='same'))\nmodel.add(Activation('relu'))\nmodel.add(Conv1D(64, 8, padding='same'))\nmodel.add(Activation('relu'))\nmodel.add(Flatten())\nmodel.add(Dense(4)) # Target class number\nmodel.add(Activation('softmax'))\nopt = keras.optimizers.SGD(lr=0.0001, momentum=0.0, decay=0.0, nesterov=False)\n#opt = keras.optimizers.Adam(lr=0.000001)\n#opt = keras.optimizers.RMSprop(lr=0.00001, decay=1e-6)\nprint(model.summary())","execution_count":11,"outputs":[{"output_type":"stream","text":"Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv1d (Conv1D)              (None, 2994, 256)         2304      \n_________________________________________________________________\nactivation (Activation)      (None, 2994, 256)         0         \n_________________________________________________________________\nconv1d_1 (Conv1D)            (None, 2994, 256)         524544    \n_________________________________________________________________\nbatch_normalization (BatchNo (None, 2994, 256)         1024      \n_________________________________________________________________\nactivation_1 (Activation)    (None, 2994, 256)         0         \n_________________________________________________________________\ndropout (Dropout)            (None, 2994, 256)         0         \n_________________________________________________________________\nmax_pooling1d (MaxPooling1D) (None, 374, 256)          0         \n_________________________________________________________________\nconv1d_2 (Conv1D)            (None, 374, 128)          262272    \n_________________________________________________________________\nactivation_2 (Activation)    (None, 374, 128)          0         \n_________________________________________________________________\nconv1d_3 (Conv1D)            (None, 374, 128)          131200    \n_________________________________________________________________\nactivation_3 (Activation)    (None, 374, 128)          0         \n_________________________________________________________________\nconv1d_4 (Conv1D)            (None, 374, 128)          131200    \n_________________________________________________________________\nbatch_normalization_1 (Batch (None, 374, 128)          512       \n_________________________________________________________________\nactivation_4 (Activation)    (None, 374, 128)          0         \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 374, 128)          0         \n_________________________________________________________________\nmax_pooling1d_1 (MaxPooling1 (None, 46, 128)           0         \n_________________________________________________________________\nconv1d_5 (Conv1D)            (None, 46, 64)            65600     \n_________________________________________________________________\nactivation_5 (Activation)    (None, 46, 64)            0         \n_________________________________________________________________\nconv1d_6 (Conv1D)            (None, 46, 64)            32832     \n_________________________________________________________________\nactivation_6 (Activation)    (None, 46, 64)            0         \n_________________________________________________________________\nflatten (Flatten)            (None, 2944)              0         \n_________________________________________________________________\ndense (Dense)                (None, 4)                 11780     \n_________________________________________________________________\nactivation_7 (Activation)    (None, 4)                 0         \n=================================================================\nTotal params: 1,163,268\nTrainable params: 1,162,500\nNon-trainable params: 768\n_________________________________________________________________\nNone\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(loss='categorical_crossentropy', optimizer=opt,metrics=[tf.keras.metrics.Recall(),tf.keras.metrics.Precision(),'accuracy'])\nhistory=model.fit(X_train, y_train, batch_size=16, epochs=60, validation_data=(X_test, y_test))\n\nhist_df = pd.DataFrame(history.history) \nhist_df.to_csv('./single_iemocap.csv')","execution_count":null,"outputs":[{"output_type":"stream","text":"Epoch 1/60\n553/553 [==============================] - 22s 40ms/step - loss: 1.3407 - recall: 0.0460 - precision: 0.4834 - accuracy: 0.3562 - val_loss: 1.3320 - val_recall: 0.0136 - val_precision: 0.4167 - val_accuracy: 0.4074\nEpoch 2/60\n553/553 [==============================] - 21s 38ms/step - loss: 1.2781 - recall: 0.0568 - precision: 0.5503 - accuracy: 0.4053 - val_loss: 1.3032 - val_recall: 0.0280 - val_precision: 0.4769 - val_accuracy: 0.4137\nEpoch 3/60\n553/553 [==============================] - 21s 38ms/step - loss: 1.2574 - recall: 0.0597 - precision: 0.5796 - accuracy: 0.4081 - val_loss: 1.2932 - val_recall: 0.0271 - val_precision: 0.4615 - val_accuracy: 0.4065\nEpoch 4/60\n553/553 [==============================] - 21s 39ms/step - loss: 1.2377 - recall: 0.0650 - precision: 0.6002 - accuracy: 0.4173 - val_loss: 1.2827 - val_recall: 0.0325 - val_precision: 0.4865 - val_accuracy: 0.4146\nEpoch 5/60\n553/553 [==============================] - 21s 38ms/step - loss: 1.2198 - recall: 0.0764 - precision: 0.6667 - accuracy: 0.4241 - val_loss: 1.2727 - val_recall: 0.0307 - val_precision: 0.4857 - val_accuracy: 0.4146\nEpoch 6/60\n553/553 [==============================] - 21s 38ms/step - loss: 1.2103 - recall: 0.0805 - precision: 0.6550 - accuracy: 0.4306 - val_loss: 1.2581 - val_recall: 0.0298 - val_precision: 0.5000 - val_accuracy: 0.4201\nEpoch 7/60\n553/553 [==============================] - 22s 39ms/step - loss: 1.2029 - recall: 0.0824 - precision: 0.6781 - accuracy: 0.4360 - val_loss: 1.2714 - val_recall: 0.0289 - val_precision: 0.4638 - val_accuracy: 0.4228\nEpoch 8/60\n553/553 [==============================] - 21s 38ms/step - loss: 1.1886 - recall: 0.0875 - precision: 0.6813 - accuracy: 0.4386 - val_loss: 1.2586 - val_recall: 0.0325 - val_precision: 0.4865 - val_accuracy: 0.4264\nEpoch 9/60\n553/553 [==============================] - 21s 39ms/step - loss: 1.1817 - recall: 0.0875 - precision: 0.6690 - accuracy: 0.4377 - val_loss: 1.2457 - val_recall: 0.0343 - val_precision: 0.5429 - val_accuracy: 0.4291\nEpoch 10/60\n553/553 [==============================] - 21s 39ms/step - loss: 1.1764 - recall: 0.0928 - precision: 0.6893 - accuracy: 0.4430 - val_loss: 1.2299 - val_recall: 0.0379 - val_precision: 0.5600 - val_accuracy: 0.4273\nEpoch 11/60\n553/553 [==============================] - 21s 38ms/step - loss: 1.1690 - recall: 0.0991 - precision: 0.7039 - accuracy: 0.4474 - val_loss: 1.2242 - val_recall: 0.0434 - val_precision: 0.5517 - val_accuracy: 0.4246\nEpoch 12/60\n553/553 [==============================] - 21s 39ms/step - loss: 1.1627 - recall: 0.1035 - precision: 0.7068 - accuracy: 0.4591 - val_loss: 1.2168 - val_recall: 0.0461 - val_precision: 0.6220 - val_accuracy: 0.4354\nEpoch 13/60\n553/553 [==============================] - 21s 38ms/step - loss: 1.1541 - recall: 0.1069 - precision: 0.7210 - accuracy: 0.4595 - val_loss: 1.2110 - val_recall: 0.0443 - val_precision: 0.5385 - val_accuracy: 0.4282\nEpoch 14/60\n553/553 [==============================] - 21s 38ms/step - loss: 1.1467 - recall: 0.1108 - precision: 0.7211 - accuracy: 0.4743 - val_loss: 1.2044 - val_recall: 0.0461 - val_precision: 0.5000 - val_accuracy: 0.4309\nEpoch 15/60\n553/553 [==============================] - 21s 39ms/step - loss: 1.1420 - recall: 0.1101 - precision: 0.7141 - accuracy: 0.4639 - val_loss: 1.2008 - val_recall: 0.0443 - val_precision: 0.5104 - val_accuracy: 0.4327\nEpoch 16/60\n553/553 [==============================] - 21s 38ms/step - loss: 1.1387 - recall: 0.1152 - precision: 0.7273 - accuracy: 0.4696 - val_loss: 1.2079 - val_recall: 0.0461 - val_precision: 0.4904 - val_accuracy: 0.4327\nEpoch 17/60\n553/553 [==============================] - 21s 38ms/step - loss: 1.1332 - recall: 0.1170 - precision: 0.7138 - accuracy: 0.4739 - val_loss: 1.1976 - val_recall: 0.0479 - val_precision: 0.5464 - val_accuracy: 0.4381\nEpoch 18/60\n553/553 [==============================] - 21s 39ms/step - loss: 1.1262 - recall: 0.1179 - precision: 0.7124 - accuracy: 0.4870 - val_loss: 1.1833 - val_recall: 0.0515 - val_precision: 0.5876 - val_accuracy: 0.4381\nEpoch 19/60\n553/553 [==============================] - 21s 38ms/step - loss: 1.1236 - recall: 0.1279 - precision: 0.7447 - accuracy: 0.4871 - val_loss: 1.1925 - val_recall: 0.0488 - val_precision: 0.5192 - val_accuracy: 0.4318\nEpoch 20/60\n553/553 [==============================] - 21s 38ms/step - loss: 1.1172 - recall: 0.1270 - precision: 0.7468 - accuracy: 0.4860 - val_loss: 1.1837 - val_recall: 0.0506 - val_precision: 0.5385 - val_accuracy: 0.4390\nEpoch 21/60\n177/553 [========>.....................] - ETA: 14s - loss: 1.1021 - recall: 0.1261 - precision: 0.7346 - accuracy: 0.4954","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_name = 'Emotion_recognition_iemocap_specAugment.h5'\nsave_dir = os.path.join(os.getcwd(),'saved_models')\nif not os.path.isdir(save_dir):\n    os.mkdir(save_dir)\nmodel_path = os.path.join(save_dir,model_name)\nmodel.save(model_path)\nprint(\"save model and weight at %s\" %model_path)\n#save model to disk\nmodel_json = model.to_json()\nwith open(\"model_json.json\", \"w\") as file:\n    file.write(model_json)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# loading json and model architecture \njson_file = open('./model_json.json', 'r')\nloaded_model_json = json_file.read()\njson_file.close()\nloaded_model = model_from_json(loaded_model_json)\n\n# load weights into new model\nloaded_model.load_weights(\"./saved_models/Emotion_recognition_iemocap_specAugment.h5\")\nprint(\"Loaded model from disk\")\n \n# Keras optimiser\nopt = keras.optimizers.SGD(lr=0.0001, momentum=0.0, decay=0.0, nesterov=False)\nloaded_model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\nscore = loaded_model.evaluate(X_test, y_test, verbose=0)\nprint(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))\n\npreds = loaded_model.predict(X_test, batch_size=16, verbose=1)\n\npreds=preds.argmax(axis=1)\n\nprint(preds)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = preds.astype(int).flatten()\npreds = (lb.inverse_transform((preds)))\npreds = pd.DataFrame({'predictedvalues': preds})\n\n# Actual labels\nactual=y_test.argmax(axis=1)\nactual = actual.astype(int).flatten()\nactual = (lb.inverse_transform((actual)))\nactual = pd.DataFrame({'actualvalues': actual})\n\n# Lets combined both of them into a single dataframe\nfinaldf = actual.join(preds)\n\n# Write out the predictions to disk\nfinaldf.to_csv('Predictions.csv', index=False)\nprint(finaldf.groupby('predictedvalues').count())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def print_confusion_matrix(confusion_matrix, class_names, figsize = (10,7), fontsize=14):\n    \"\"\"Prints a confusion matrix, as returned by sklearn.metrics.confusion_matrix, as a heatmap.\n    \n    Arguments\n    ---------\n    confusion_matrix: numpy.ndarray\n        The numpy.ndarray object returned from a call to sklearn.metrics.confusion_matrix. \n        Similarly constructed ndarrays can also be used.\n    class_names: list\n        An ordered list of class names, in the order they index the given confusion matrix.\n    figsize: tuple\n        A 2-long tuple, the first value determining the horizontal size of the ouputted figure,\n        the second determining the vertical size. Defaults to (10,7).\n    fontsize: int\n        Font size for axes labels. Defaults to 14.\n        \n    Returns\n    -------\n    matplotlib.figure.Figure\n        The resulting confusion matrix figure\n    \"\"\"\n    df_cm = pd.DataFrame(\n        confusion_matrix, index=class_names, columns=class_names, \n    )\n    fig = plt.figure(figsize=figsize)\n    try:\n        heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n    except ValueError:\n        raise ValueError(\"Confusion matrix values must be integers.\")\n        \n    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=fontsize)\n    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize=fontsize)\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"finaldf = pd.read_csv(\"./Predictions.csv\")\nclasses = finaldf.actualvalues.unique()\nclasses.sort()    \nfrom sklearn.metrics import confusion_matrix, accuracy_score, classification_report\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n# Confusion matrix \nc = confusion_matrix(finaldf.actualvalues, finaldf.predictedvalues)\nprint(accuracy_score(finaldf.actualvalues, finaldf.predictedvalues))\nplt.show(print_confusion_matrix(c, class_names = classes))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Classification report \nclasses = finaldf.actualvalues.unique()\nclasses.sort()    \nprint(classification_report(finaldf.actualvalues, finaldf.predictedvalues, target_names=classes))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history_df = pd.read_csv('./specAugment_iemocap.csv')\nhistory_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(history_df.accuracy)\nplt.plot(history_df.val_accuracy)\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(history_df.loss)\nplt.plot(history_df.val_loss)\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}